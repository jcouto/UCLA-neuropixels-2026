{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06089076",
   "metadata": {},
   "source": [
    "## Running Spike interface on data preprocessed with CatGT\n",
    "\n",
    "The processed data will be saved to: ``<destination parent>/<run_name>_g<gate>``. Open it up in the SpikeGLX viewer and look for any problems. Is the background subtraction sufficient? Are any major artifacts removed?\n",
    "\n",
    "After checking that the preprocessed data looks OK, move to sorting a single shank, using spike interface\n",
    "\n",
    "\n",
    "Check the instructions [**here**](https://spikeinterface.readthedocs.io/en/0.93.0/overview.html).\n",
    "\n",
    "__spikeinterface__ is installed in the npix-analysis environment on the _course computers_; the installation instructions are [**here**](https://spikeinterface.readthedocs.io/en/0.93.0/installation.html).\n",
    "\n",
    "Be sure to checkout the other [tutorials](https://spikeinterface.readthedocs.io/en/0.93.0/getting_started/plot_getting_started.html#).\n",
    "\n",
    "---\n",
    "\n",
    "We will build and run a pipeline on this notebook, it is based on the [how to guide](https://spikeinterface.readthedocs.io/en/latest/how_to/analyze_neuropixels.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b33324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "os_str='Windows'\n",
    "\n",
    "# set the parent path for the software on your computer\n",
    "software_download_path = r'C:\\Users\\labadmin\\Desktop\\software_downloads'\n",
    "\n",
    "# parent folder of the data\n",
    "data_parent = r'C:\\Users\\labadmin\\Desktop\\test_data'\n",
    "\n",
    "# run name for the acquired data (don't include any gate info)\n",
    "run_name = 'SC035_010720_ex'\n",
    "\n",
    "# gate index (for myrun_g0_t0.imec0.ap.bin, the gate = 0)\n",
    "gate = 0\n",
    "\n",
    "# destination parent\n",
    "dest_parent = r'C:\\Users\\labadmin\\Desktop\\test_data\\output'\n",
    "\n",
    "# time to analyze and sort \n",
    "maxsecs = 600\n",
    "\n",
    "# extraction parameters for stimulus times. parameters: stream type(js), stream index(ip), channel in file, threshold1, threshold2, duration\n",
    "obx_ex_str = '-xa=1,0,1,1,3,50'\n",
    "\n",
    "dest_dir = os.path.join(dest_parent,f'{run_name}_g{gate}')\n",
    "if not os.path.isdir(dest_dir):\n",
    "    os.mkdir(dest_dir)\n",
    "\n",
    "cmd_parts = list()\n",
    "cmd_parts.append(os.path.join(software_download_path,'ecephys_course/CatGT-win/CatGT.exe'))\n",
    "cmd_parts.append(f'-dir={data_parent} -run={run_name} -g={gate} -t=0,0 -prb_fld')\n",
    "cmd_parts.append(f'-prb=0 -ap')\n",
    "cmd_parts.append(f'-apfilter=butter,12,300,10000 -gblcar -gfix=0.40,0.10,0.02')\n",
    "#cmd_parts.append(f'-ob {obx_ex_str}')\n",
    "cmd_parts.append(f'-maxsecs={maxsecs}')\n",
    "cmd_parts.append(f'-out_prb_fld -no_catgt_fld -dest={dest_dir}')\n",
    "                        \n",
    "\n",
    "catGT_cmd = ' '        # use space as the separator for the command parts\n",
    "catGT_cmd = catGT_cmd.join(cmd_parts[1:len(cmd_parts)]) # these are the parameters\n",
    "if os_str=='linux':\n",
    "    # enclose the params in single quotes, so curly braces will not be interpreted by Linux\n",
    "    catGT_cmd = f\"{cmd_parts[0]} '{catGT_cmd}'\"\n",
    "else:\n",
    "    catGT_cmd = f\"{cmd_parts[0]} {catGT_cmd}\"\n",
    "\n",
    "print(catGT_cmd)\n",
    "subprocess.Popen(catGT_cmd,shell='False').wait()\n",
    "print('CatGT complete, check CatGT.log in notebook folder for errors.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733935a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.full as si\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# parameters -- these only pertain to the sorter, because the data is already preprocessed.\n",
    "# in this example, we keep the filtering and whitening in Kilosort 4. This is to keep the native Ks4 whitening (to avoid scaling problems)\n",
    "\n",
    "ks4_params = si.get_default_sorter_params('kilosort4')\n",
    "ks4_params['do_CAR'] = False # skip CAR in kilosort\n",
    "job_kwargs = dict(n_jobs=-1, chunk_duration='1s', progress_bar=True) # how to chunk and process data\n",
    "\n",
    "sort_folder = os.path.join(dest_dir,f'ks4_out')  # this folder is created by KS4; existing folder cannot be overwritten\n",
    "\n",
    "# load spikeglx data, pointing to the destination folder created above\n",
    "stream_names, stream_ids = si.get_neo_streams('spikeglx', dest_dir)\n",
    "\n",
    "print(f'There are streams {stream_names} in folder {dest_dir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e55cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET the stream parameter for the file you want to sort here\n",
    "\n",
    "selected_stream = 'imec0.ap'\n",
    "\n",
    "print(f'All Kilosort4 parameters are: ')\n",
    "for k in ks4_params.keys():\n",
    "    print(f'   - {k}: {ks4_params[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the stream for the selected shank\n",
    "\n",
    "rec = si.read_spikeglx(dest_dir, stream_name=selected_stream, load_sync_channel=False)\n",
    "\n",
    "# run ks4\n",
    "sorting = si.run_sorter('kilosort4', rec, folder=sort_folder,\n",
    "                        docker_image=False, verbose=True, **ks4_params)\n",
    "sorting = si.read_sorter_folder(sort_folder)\n",
    "\n",
    "# phy output from ks4 is saved to sort_folder/sorter_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318cf681-bb96-4f14-8f33-74a7569fe9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average waveforms and metrics.\n",
    "\n",
    "sorting = si.read_sorter_folder(sort_folder)\n",
    "\n",
    "analyzer = si.create_sorting_analyzer(sorting, rec, sparse=True, format=\"memory\")\n",
    "# compute waveforms \n",
    "analyzer.compute(\"random_spikes\", method=\"uniform\", max_spikes_per_unit=500)\n",
    "analyzer.compute(\"waveforms\",  ms_before=1.5, ms_after=1.5, **job_kwargs)\n",
    "analyzer.compute(\"templates\", operators=[\"average\", \"median\", \"std\"])\n",
    "analyzer.compute(\"noise_levels\")\n",
    "analyzer.compute(\"correlograms\")\n",
    "analyzer.compute(\"unit_locations\")\n",
    "analyzer.compute(\"spike_amplitudes\", **job_kwargs)\n",
    "\n",
    "# quality metrics\n",
    "metric_names=['firing_rate', 'presence_ratio', 'snr', 'isi_violation', 'amplitude_cutoff']\n",
    "metrics = si.compute_quality_metrics(analyzer, metric_names=metric_names)\n",
    "\n",
    "# all of the analyzer computed quantitites are saved in sort_folder/analyzer/extensions\n",
    "analyzer_saved = analyzer.save_as(folder=os.path.join(sort_folder, \"analyzer\"), format=\"binary_folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4c2312-0a98-4e06-9265-ac346e1c69d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
