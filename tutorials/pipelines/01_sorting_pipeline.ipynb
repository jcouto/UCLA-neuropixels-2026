{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "509027b4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Running **spike sorting** pipelines:\n",
    "\n",
    "A spike sorting pipeline for neuropixels should consist of:\n",
    "\n",
    " - preprocessing (phase_shifting, filtering, denoising..)\n",
    " - motion correction\n",
    " - the actual sorting (assigning spikes to units)\n",
    " - waveform extraction\n",
    " - metric computation\n",
    "\n",
    "and some other optional steps like reading __sycnchronization channels__, __manual curation__ and result inspection.\n",
    "\n",
    "### ecephys spike sorting\n",
    "\n",
    "Check the usage instructions [**here**](https://github.com/jenniferColonell/ecephys_spike_sorting#usage).\n",
    "\n",
    "__ecephys__ is installed on the _course computers_; the installation instructions are [**here**](https://github.com/jenniferColonell/ecephys_spike_sorting#installation-with-anaconda-and-kilosort4); don't forget to install _CatGT_ and set the paths in the ``ecephys_spike_sorting\\ecephys_spike_sorting\\scripts\\create_input_json.py`` file if you are installing from scratch. \n",
    "\n",
    "---\n",
    "\n",
    "To **configure** the pipeline to run the test data you need to edit the file ``sglx_multi_run_pipeline.py`` in the ``ecephys_spike_sorting\\ecephys_spike_sorting\\scripts`` directory.\n",
    "\n",
    "In the _course computers_ that file is in: ``C\\Users\\np_user\\Desktop\\software_downloads\\ecephys_course\\ecephys_spike_sorting\\ecephys_spike_sorting\\scripts`` \n",
    "\n",
    "The file (**sglx_multi_run_pipeline.py**) controls most aspects of the pipeline. Some things to check:\n",
    " 1. __line 67__: ``npx_directory = r'<PARENT DIRECTORY OF THE INPUT (e.g. C:\\SGL_DATA)' `` \n",
    " 2. __line 95 to 97__: ``run_specs = [['<FILEPART NAME BEFORE THE GATE WITHOUT UNDERSCORE`, '<GATE NUMBER', '0,0', '0', '0', ['cortex','thalamus','thalamus'] ]``  specifies the file and gate to run, add multiple lines to concatenate gates or sessions\n",
    "\n",
    " 3. __line 105__: ``catGT_dest = r'<PATH TO AN EMPTY FOLDER>'`` don't forget to create the folder. this is the output path.\n",
    " 4. __line 216__: ``json_directory = r'<PATH TO THE OUTPUT WHERE TO STORE JSON FILES>'`` this can be the same folder as point 3 or another if you want the files to be separate.\n",
    " 5. __line 135 to 136__: ``obx_present = True`` set to true to analyze the OneBox channels ``ni_present = False`` to analyze obx channels\n",
    " 6. __line 137__: ``ni_obx_extract_string = '-xa=1,0,1,1,3,50`` extract the 50 ms pulses that mark trial start    \n",
    "\n",
    "---\n",
    "\n",
    "To **run**:\n",
    " - open a terminal where you can run conda commands. \n",
    " - activate the environment ``conda activate ecephys_ks4`` _in the course_.\n",
    " - go to the folder that has the ``sglx_multi_run_pipeline.py`` file using ``cd <FOLDERPATH>``\n",
    " - run the pipeline ``python sglx_multi_run_pipeline.py``\n",
    "\n",
    "\n",
    " ---\n",
    "\n",
    " To **visualize** the results:\n",
    "\n",
    "You can visualize with [**phy**](https://github.com/cortex-lab/phy).\n",
    "\n",
    " - open a terminal where you can run conda commands. \n",
    " - activate the environment ``conda activate phy2`` _in the course_.\n",
    " - go to the output folder using ``cd <FOLDERPATH>`` you want the folder that has the **params.py** file.\n",
    " - open phy using the command **``phy template-gui params.py``**\n",
    "\n",
    "\n",
    "You can analyze the visual responses in the notebook 03_visual_responses.ipynb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f77606-a36f-4f89-877e-52152a4573ca",
   "metadata": {},
   "source": [
    "### Combining tools to build a pipeline\n",
    "\n",
    "## Building a CatGT command line for preprocessing\n",
    "Preprocessing can also be done in Spikeinterface -- here we use CatGT to handle a few SGLX details more easily.\n",
    "Here we build a CatGT command line to process your data, then look at the result with the SpikeGLX viewer. \n",
    "For more details on CatGT, see the help [**here**](https://billkarsh.github.io/SpikeGLX/CatGT_help/CatGT_ReadMe.html).\n",
    "\n",
    "This is also a general model for incorporating command line or other compiled tools into a simple python notebook or script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea774f8d-bc06-44b1-b753-46fbab2f08f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\labadmin\\Desktop\\software\\ecephys_course/CatGT-win/CatGT.exe -dir=C:\\SGL_DATA\\Group4_bank0_kc\\KS001_V1_011526_KC_g0 -run=KS001_V1_011526_KC_g0 -g=0 -t=0,0 -prb_fld -prb=0 -ap -apfilter=butter,12,300,10000 -gblcar -gfix=0.40,0.10,0.02 -maxsecs=600 -out_prb_fld -no_catgt_fld -dest=C:\\Users\\np_user\\Desktop\\test_data\\output\\KS001_V1_011526_KC_g0_g0\n",
      "CatGT complete, check CatGT.log in notebook folder for errors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "os_str='Windows'\n",
    "\n",
    "# set the parent path for the software on your computer\n",
    "software_download_path = r'C:\\Users\\labadmin\\Desktop\\software'\n",
    "\n",
    "# parent folder of the data\n",
    "data_parent = r'C:\\SGL_DATA\\Group4_bank0_kc\\KS001_V1_011526_KC_g0'\n",
    "\n",
    "# run name for the acquired data (don't include any gate info)\n",
    "run_name = 'KS001_V1_011526_KC_g0'\n",
    "\n",
    "# gate index (for myrun_g0_t0.imec0.ap.bin, the gate = 0)\n",
    "gate = 0\n",
    "\n",
    "# destination parent\n",
    "dest_parent = r'C:\\Users\\np_user\\Desktop\\test_data\\output'\n",
    "Path(dest_parent).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "\n",
    "    \n",
    "# time to analyze and sort \n",
    "maxsecs = 600\n",
    "\n",
    "# extraction parameters for stimulus times. parameters: stream type(js), stream index(ip), channel in file, threshold1, threshold2, duration\n",
    "obx_ex_str = '-xa=1,0,1,1,3,50'\n",
    "\n",
    "dest_dir = os.path.join(dest_parent,f'{run_name}_g{gate}')\n",
    "if not os.path.isdir(dest_dir):\n",
    "    os.mkdir(dest_dir)\n",
    "\n",
    "cmd_parts = list()\n",
    "cmd_parts.append(os.path.join(software_download_path,'ecephys_course/CatGT-win/CatGT.exe'))\n",
    "cmd_parts.append(f'-dir={data_parent} -run={run_name} -g={gate} -t=0,0 -prb_fld')\n",
    "cmd_parts.append(f'-prb=0 -ap')\n",
    "cmd_parts.append(f'-apfilter=butter,12,300,10000 -gblcar -gfix=0.40,0.10,0.02')\n",
    "#cmd_parts.append(f'-ob {obx_ex_str}')\n",
    "cmd_parts.append(f'-maxsecs={maxsecs}')\n",
    "cmd_parts.append(f'-out_prb_fld -no_catgt_fld -dest={dest_dir}')\n",
    "                        \n",
    "\n",
    "catGT_cmd = ' '        # use space as the separator for the command parts\n",
    "catGT_cmd = catGT_cmd.join(cmd_parts[1:len(cmd_parts)]) # these are the parameters\n",
    "if os_str=='linux':\n",
    "    # enclose the params in single quotes, so curly braces will not be interpreted by Linux\n",
    "    catGT_cmd = f\"{cmd_parts[0]} '{catGT_cmd}'\"\n",
    "else:\n",
    "    catGT_cmd = f\"{cmd_parts[0]} {catGT_cmd}\"\n",
    "\n",
    "print(catGT_cmd)\n",
    "subprocess.Popen(catGT_cmd,shell='False').wait()\n",
    "print('CatGT complete, check CatGT.log in notebook folder for errors.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06089076",
   "metadata": {},
   "source": [
    "### Running Spike interface on preprocessed data\n",
    "\n",
    "The processed data will be saved to: ``<destination parent>/<run_name>_g<gate>``. Open it up in the SpikeGLX viewer and look for any problems. Is the background subtraction sufficient? Are any major artifacts removed?\n",
    "\n",
    "After checking that the preprocessed data looks OK, move to sorting a single shank, using spike interface\n",
    "\n",
    "\n",
    "Check the instructions [**here**](https://spikeinterface.readthedocs.io/en/0.93.0/overview.html).\n",
    "\n",
    "__spikeinterface__ is installed in the npix-analysis environment on the _course computers_; the installation instructions are [**here**](https://spikeinterface.readthedocs.io/en/0.93.0/installation.html).\n",
    "\n",
    "Be sure to checkout the other [tutorials](https://spikeinterface.readthedocs.io/en/0.93.0/getting_started/plot_getting_started.html#).\n",
    "\n",
    "---\n",
    "\n",
    "We will build and run a pipeline on this notebook, it is based on the [how to guide](https://spikeinterface.readthedocs.io/en/latest/how_to/analyze_neuropixels.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "733935a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No appropriate combination of .meta and .bin files were detected in C:\\Users\\np_user\\Desktop\\test_data\\output\\KS001_V1_011526_KC_g0_g0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m sort_folder = os.path.join(dest_dir,\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mks4_out\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# this folder is created by KS4; existing folder cannot be overwritten\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# load spikeglx data, pointing to the destination folder created above\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m stream_names, stream_ids = \u001b[43msi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_neo_streams\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mspikeglx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThere are streams \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstream_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in folder \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdest_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniforge3\\envs\\npix-analysis\\Lib\\site-packages\\spikeinterface\\extractors\\neoextractors\\neo_utils.py:28\u001b[39m, in \u001b[36mget_neo_streams\u001b[39m\u001b[34m(extractor_name, *args, **kwargs)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns the NEO streams (stream names and stream ids) associated to a dataset.\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03mFor multi-stream datasets, the `stream_id` or `stream_name` arguments can be used\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03mto select which stream to read with the `read_**extractor_name**()` function.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m \u001b[33;03m    List of NEO stream ids\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     27\u001b[39m neo_extractor = get_neo_extractor(extractor_name)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mneo_extractor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_streams\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniforge3\\envs\\npix-analysis\\Lib\\site-packages\\spikeinterface\\extractors\\neoextractors\\neobaseextractor.py:73\u001b[39m, in \u001b[36m_NeoBaseExtractor.get_streams\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_streams\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *args, **kwargs):\n\u001b[32m     72\u001b[39m     neo_kwargs = \u001b[38;5;28mcls\u001b[39m.map_to_neo_kwargs(*args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     neo_reader = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_neo_io_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mNeoRawIOClass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mneo_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     stream_channels = neo_reader.header[\u001b[33m\"\u001b[39m\u001b[33msignal_streams\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     76\u001b[39m     stream_names = stream_channels[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m].tolist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniforge3\\envs\\npix-analysis\\Lib\\site-packages\\spikeinterface\\extractors\\neoextractors\\neobaseextractor.py:66\u001b[39m, in \u001b[36m_NeoBaseExtractor.get_neo_io_reader\u001b[39m\u001b[34m(cls, raw_class, **neo_kwargs)\u001b[39m\n\u001b[32m     64\u001b[39m neoIOclass = \u001b[38;5;28mgetattr\u001b[39m(rawio_module, raw_class)\n\u001b[32m     65\u001b[39m neo_reader = neoIOclass(**neo_kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[43mneo_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m neo_reader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniforge3\\envs\\npix-analysis\\Lib\\site-packages\\neo\\rawio\\baserawio.py:211\u001b[39m, in \u001b[36mBaseRawIO.parse_header\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[33;03mParses the header of the file(s) to allow for faster computations\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[33;03mfor all other functions\u001b[39;00m\n\u001b[32m    200\u001b[39m \n\u001b[32m    201\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# this must create\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;66;03m# self.header['nb_block']\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[38;5;66;03m# self.header['nb_segment']\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# self.header['spike_channels']\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m# self.header['event_channels']\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;28mself\u001b[39m._check_stream_signal_channel_characteristics()\n\u001b[32m    213\u001b[39m \u001b[38;5;28mself\u001b[39m.is_header_parsed = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniforge3\\envs\\npix-analysis\\Lib\\site-packages\\neo\\rawio\\spikeglxrawio.py:128\u001b[39m, in \u001b[36mSpikeGLXRawIO._parse_header\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_parse_header\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28mself\u001b[39m.signals_info_list = \u001b[43mscan_files\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m     _add_segment_order(\u001b[38;5;28mself\u001b[39m.signals_info_list)\n\u001b[32m    131\u001b[39m     \u001b[38;5;66;03m# sort stream_name by higher sampling rate first\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniforge3\\envs\\npix-analysis\\Lib\\site-packages\\neo\\rawio\\spikeglxrawio.py:410\u001b[39m, in \u001b[36mscan_files\u001b[39m\u001b[34m(dirname)\u001b[39m\n\u001b[32m    407\u001b[39m             info_list.append(info)\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(info_list) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo appropriate combination of .meta and .bin files were detected in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m info_list\n",
      "\u001b[31mFileNotFoundError\u001b[39m: No appropriate combination of .meta and .bin files were detected in C:\\Users\\np_user\\Desktop\\test_data\\output\\KS001_V1_011526_KC_g0_g0"
     ]
    }
   ],
   "source": [
    "import spikeinterface.full as si\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# parameters -- these only pertain to the sorter, because the data is already preprocessed.\n",
    "# in this example, we keep the filtering and whitening in Kilosort 4. This is to keep the native Ks4 whitening (to avoid scaling problems)\n",
    "\n",
    "ks4_params = si.get_default_sorter_params('kilosort4')\n",
    "ks4_params['do_CAR'] = False # skip CAR in kilosort\n",
    "job_kwargs = dict(n_jobs=-1, chunk_duration='1s', progress_bar=True) # how to chunk and process data\n",
    "\n",
    "sort_folder = os.path.join(dest_dir,f'ks4_out')  # this folder is created by KS4; existing folder cannot be overwritten\n",
    "\n",
    "# load spikeglx data, pointing to the destination folder created above\n",
    "stream_names, stream_ids = si.get_neo_streams('spikeglx', dest_dir)\n",
    "\n",
    "print(f'There are streams {stream_names} in folder {dest_dir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ac1f37-dc90-4ffb-812d-8f13caef905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET the stream parameter for the file you want to sort here\n",
    "\n",
    "selected_stream = 'imec0.ap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e55cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'All Kilosort4 parameters are: ')\n",
    "for k in ks4_params.keys():\n",
    "    print(f'   - {k}: {ks4_params[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the stream for the selected shank\n",
    "\n",
    "rec = si.read_spikeglx(dest_dir, stream_name=selected_stream, load_sync_channel=False)\n",
    "\n",
    "# run ks4\n",
    "sorting = si.run_sorter('kilosort4', rec, folder=sort_folder,\n",
    "                        docker_image=False, verbose=True, **ks4_params)\n",
    "sorting = si.read_sorter_folder(sort_folder)\n",
    "\n",
    "# phy output from ks4 is saved to sort_folder/sorter_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318cf681-bb96-4f14-8f33-74a7569fe9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average waveforms and metrics.\n",
    "\n",
    "sorting = si.read_sorter_folder(sort_folder)\n",
    "\n",
    "analyzer = si.create_sorting_analyzer(sorting, rec, sparse=True, format=\"memory\")\n",
    "# compute waveforms \n",
    "analyzer.compute(\"random_spikes\", method=\"uniform\", max_spikes_per_unit=500)\n",
    "analyzer.compute(\"waveforms\",  ms_before=1.5, ms_after=1.5, **job_kwargs)\n",
    "analyzer.compute(\"templates\", operators=[\"average\", \"median\", \"std\"])\n",
    "analyzer.compute(\"noise_levels\")\n",
    "analyzer.compute(\"correlograms\")\n",
    "analyzer.compute(\"unit_locations\")\n",
    "analyzer.compute(\"spike_amplitudes\", **job_kwargs)\n",
    "\n",
    "# quality metrics\n",
    "metric_names=['firing_rate', 'presence_ratio', 'snr', 'isi_violation', 'amplitude_cutoff']\n",
    "metrics = si.compute_quality_metrics(analyzer, metric_names=metric_names)\n",
    "\n",
    "# all of the analyzer computed quantitites are saved in sort_folder/analyzer/extensions\n",
    "analyzer_saved = analyzer.save_as(folder=os.path.join(sort_folder, \"analyzer\"), format=\"binary_folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4c2312-0a98-4e06-9265-ac346e1c69d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
